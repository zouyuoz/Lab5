{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTnnWBbcLNF9"
      },
      "source": [
        "# 2025 DL Lab5: Object Detection on Pascal VOC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0X5a8hdLNF_"
      },
      "source": [
        "**Your Answer:**    \n",
        "Hi I'm 邱照元, 314834001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5471631f"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "# !kaggle competitions download -c lab-5-object-detection-on-pascal-voc-639401\n",
        "# !unzip -q lab-5-object-detection-on-pascal-voc-639401"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # latest repo\n",
        "# import shutil\n",
        "\n",
        "# REPO_URL = \"https://github.com/zouyuoz/Lab5\"\n",
        "# REPO_NAME = \"Lab5\"\n",
        "# TARGET_DIR = \"/content\"\n",
        "# CLONE_DIR = os.path.join(TARGET_DIR, REPO_NAME)\n",
        "\n",
        "# !git clone {REPO_URL} {CLONE_DIR}\n",
        "# !rsync -aq --remove-source-files {CLONE_DIR}/ {TARGET_DIR}/\n",
        "# !rm -rf {CLONE_DIR}\n",
        "# os.chdir(TARGET_DIR)\n",
        "# print(f\"\\n✅ 專案設定完成。目前工作目錄：{os.getcwd()}\")"
      ],
      "metadata": {
        "id": "DMQuuUjV5abr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f06bd394"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "REPO_URL = \"https://github.com/zouyuoz/Lab5\"\n",
        "REPO_NAME = \"Lab5\"\n",
        "TARGET_DIR = \"/content\"\n",
        "CLONE_DIR = os.path.join(TARGET_DIR, REPO_NAME)\n",
        "TARGET_SHA = \"29107facfe63a579f482839124d599bfd615bb5e\"\n",
        "\n",
        "!git clone {REPO_URL} {CLONE_DIR}\n",
        "%cd {CLONE_DIR}\n",
        "!git checkout {TARGET_SHA}\n",
        "\n",
        "!rsync -aq --remove-source-files . {TARGET_DIR}/\n",
        "%cd {TARGET_DIR} # 切換回 TARGET_DIR\n",
        "!rm -rf {CLONE_DIR}\n",
        "os.chdir(TARGET_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ViIYGZBLNGB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.amp import autocast, GradScaler\n",
        "from src.yolo import getODmodel\n",
        "from yolo_loss import YOLOv3Loss\n",
        "from yolo_loss_ciou_focal import YOLOv3Loss_CIoU_Focal\n",
        "from src.dataset import VocDetectorDataset, train_data_pipelines, test_data_pipelines, collate_fn\n",
        "from src.eval_voc import evaluate\n",
        "from src.config import GRID_SIZES, ANCHORS\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmP2FGeqLNGB"
      },
      "outputs": [],
      "source": [
        "##### hyperparameters #####\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 50\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "lambda_coord=5.0\n",
        "lambda_obj=1.0\n",
        "lambda_noobj=0.5\n",
        "lambda_class=1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C7j0i7TLNGC",
        "outputId": "dc8d1217-d7bb-4dab-d5f3-3d10c5494b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "Initializing dataset\n",
            "Loaded 8218 train images\n",
            "Initializing dataset\n",
            "Initializing dataset\n",
            "Loaded 3823 val images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Data paths\n",
        "file_root_train = './dataset/image/'\n",
        "annotation_file_train = './dataset/vocall_train.txt'\n",
        "file_root_val = './dataset/image/'\n",
        "annotation_file_val = './dataset/vocall_val.txt'\n",
        "\n",
        "# Create datasets\n",
        "print('Loading datasets...')\n",
        "train_dataset = VocDetectorDataset(\n",
        "    root_img_dir=file_root_train, dataset_file=annotation_file_train, train=True,\n",
        "    transform=train_data_pipelines, grid_sizes=GRID_SIZES, encode_target=True\n",
        ")\n",
        "val_dataset = VocDetectorDataset(\n",
        "    root_img_dir=file_root_val, dataset_file=annotation_file_val, train=False,\n",
        "    transform=test_data_pipelines, grid_sizes=GRID_SIZES, encode_target=True,\n",
        ")\n",
        "eval_dataset = VocDetectorDataset(\n",
        "    root_img_dir=file_root_val, dataset_file=annotation_file_val, train=False,\n",
        "    transform=test_data_pipelines, grid_sizes=GRID_SIZES, encode_target=False,\n",
        ")\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True, num_workers=4,)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False, num_workers=4,)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False, num_workers=4)\n",
        "\n",
        "print(f'Loaded {len(train_dataset)} train images')\n",
        "print(f'Loaded {len(val_dataset)} val images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xZz0TyDLNGC"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVM7m3HELNGC",
        "outputId": "a32e9432-75bb-4f72-f9f8-c7fd04751c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:timm.models._builder:Unexpected keys (bn2.num_batches_tracked, bn2.bias, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
          ]
        }
      ],
      "source": [
        "load_network_path = None #'checkpoints/best_detector.pth'\n",
        "pretrained = True\n",
        "model = getODmodel(pretrained=pretrained).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rpsL4dwLNGC"
      },
      "source": [
        "### Some training utils, use mix precision if valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAOM35usLNGC"
      },
      "outputs": [],
      "source": [
        "# Create loss and optimizer\n",
        "# criterion = YOLOv3Loss(lambda_coord, lambda_obj, lambda_noobj, lambda_class, ANCHORS).to(device)\n",
        "# criterion = YOLOv3Loss_CIoU_Focal(lambda_coord=lambda_coord, lambda_noobj=lambda_noobj, anchors=ANCHORS)\n",
        "criterion = YOLOv3Loss_CIoU_Focal(anchors=ANCHORS)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
        "lr_scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
        "use_amp = torch.cuda.is_available()\n",
        "scaler = GradScaler(enabled=use_amp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWHsdriGLNGD"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WSZPne-hLNGD",
        "outputId": "c7b5675c-bc9c-46ea-9a28-26806eafa6aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training...\n",
            "\n",
            "Starting epoch 1 / 50\n",
            "Grad norm: 181455.63\n",
            "Epoch [1/50], Iter [40/129], Loss: total=1.534, box=55.984, obj=7269.431, noobj=7240.567, cls=63.296, num_pos=176.000, num_neg=681232.000, B=64.000\n",
            "Grad norm: 143394.76\n",
            "Epoch [1/50], Iter [80/129], Loss: total=1.261, box=65.411, obj=3107.966, noobj=3070.416, cls=62.763, num_pos=217.000, num_neg=681191.000, B=64.000\n",
            "Grad norm: 176582.50\n",
            "Epoch [1/50], Iter [120/129], Loss: total=1.148, box=51.714, obj=2340.566, noobj=2316.039, cls=53.893, num_pos=177.000, num_neg=681231.000, B=64.000\n",
            "Learning Rate for this epoch: 9.990e-04\n",
            "Validation Loss: 1.1631\n",
            "Updating best val loss: 1.16311\n",
            "\n",
            "Starting epoch 2 / 50\n",
            "Grad norm: 193757.36\n",
            "Epoch [2/50], Iter [40/129], Loss: total=1.030, box=42.227, obj=1878.737, noobj=1855.515, cls=45.749, num_pos=163.000, num_neg=681245.000, B=64.000\n",
            "Grad norm: 218832.86\n",
            "Epoch [2/50], Iter [80/129], Loss: total=1.104, box=57.116, obj=1622.171, noobj=1593.565, cls=52.877, num_pos=193.000, num_neg=681215.000, B=64.000\n",
            "Grad norm: 159537.37\n",
            "Epoch [2/50], Iter [120/129], Loss: total=0.994, box=49.159, obj=1426.564, noobj=1402.339, cls=48.999, num_pos=187.000, num_neg=681221.000, B=64.000\n",
            "Learning Rate for this epoch: 9.961e-04\n",
            "Validation Loss: 1.0140\n",
            "Updating best val loss: 1.01402\n",
            "\n",
            "Starting epoch 3 / 50\n",
            "Grad norm: 153768.79\n",
            "Epoch [3/50], Iter [40/129], Loss: total=0.893, box=44.602, obj=1372.921, noobj=1352.671, cls=43.637, num_pos=187.000, num_neg=681221.000, B=64.000\n",
            "Grad norm: 170994.40\n",
            "Epoch [3/50], Iter [80/129], Loss: total=0.909, box=41.964, obj=1417.220, noobj=1399.632, cls=38.858, num_pos=167.000, num_neg=681241.000, B=64.000\n",
            "Grad norm: 160610.54\n",
            "Epoch [3/50], Iter [120/129], Loss: total=0.866, box=44.277, obj=1313.088, noobj=1295.113, cls=44.353, num_pos=190.000, num_neg=681218.000, B=64.000\n",
            "Learning Rate for this epoch: 9.912e-04\n",
            "Validation Loss: 0.9312\n",
            "Updating best val loss: 0.93120\n",
            "\n",
            "Starting epoch 4 / 50\n",
            "Grad norm: 159434.67\n",
            "Epoch [4/50], Iter [40/129], Loss: total=0.946, box=54.646, obj=1066.475, noobj=1037.067, cls=53.147, num_pos=218.000, num_neg=681190.000, B=64.000\n",
            "Grad norm: 180273.82\n",
            "Epoch [4/50], Iter [80/129], Loss: total=0.860, box=42.008, obj=1201.811, noobj=1181.258, cls=45.616, num_pos=189.000, num_neg=681219.000, B=64.000\n",
            "Grad norm: 136681.30\n",
            "Epoch [4/50], Iter [120/129], Loss: total=0.926, box=52.205, obj=1261.161, noobj=1239.964, cls=45.802, num_pos=201.000, num_neg=681207.000, B=64.000\n",
            "Learning Rate for this epoch: 9.843e-04\n",
            "Validation Loss: 0.8825\n",
            "Updating best val loss: 0.88250\n",
            "\n",
            "Starting epoch 5 / 50\n",
            "Grad norm: 131043.99\n",
            "Epoch [5/50], Iter [40/129], Loss: total=0.933, box=62.979, obj=1134.549, noobj=1100.937, cls=56.441, num_pos=254.000, num_neg=681154.000, B=64.000\n",
            "Grad norm: 177294.36\n",
            "Epoch [5/50], Iter [80/129], Loss: total=0.783, box=38.557, obj=1053.877, noobj=1038.365, cls=34.402, num_pos=174.000, num_neg=681234.000, B=64.000\n",
            "Grad norm: 140663.24\n",
            "Epoch [5/50], Iter [120/129], Loss: total=0.818, box=46.270, obj=952.576, noobj=929.881, cls=43.900, num_pos=209.000, num_neg=681199.000, B=64.000\n",
            "Learning Rate for this epoch: 9.756e-04\n",
            "Validation Loss: 0.8482\n",
            "Updating best val loss: 0.84817\n",
            "\n",
            "Evaluating on validation set...\n",
            "---Evaluate model on validation samples---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [00:40<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21962 AP of class aeroplane\n",
            "0.14098 AP of class bicycle\n",
            "0.16970 AP of class bird\n",
            "0.00000 AP of class boat (no predictions for this class)\n",
            "0.00000 AP of class bottle (no predictions for this class)\n",
            "0.00000 AP of class bus (no predictions for this class)\n",
            "0.20703 AP of class car\n",
            "0.22023 AP of class cat\n",
            "0.00196 AP of class chair\n",
            "0.00000 AP of class cow (no predictions for this class)\n",
            "0.20392 AP of class diningtable\n",
            "0.07137 AP of class dog\n",
            "0.20762 AP of class horse\n",
            "0.09713 AP of class motorbike\n",
            "0.30490 AP of class person\n",
            "0.00000 AP of class pottedplant (no predictions for this class)\n",
            "0.00000 AP of class sheep (no predictions for this class)\n",
            "0.03791 AP of class sofa\n",
            "0.31962 AP of class train\n",
            "0.00000 AP of class tvmonitor (no predictions for this class)\n",
            "--- MAP: 0.11010 ---\n",
            "Epoch 5, mAP: 0.1101\n",
            "\n",
            "Starting epoch 6 / 50\n",
            "Grad norm: 181219.26\n",
            "Epoch [6/50], Iter [40/129], Loss: total=0.784, box=34.836, obj=985.916, noobj=972.492, cls=32.253, num_pos=156.000, num_neg=681252.000, B=64.000\n",
            "Grad norm: 153733.25\n",
            "Epoch [6/50], Iter [80/129], Loss: total=0.810, box=39.402, obj=1062.627, noobj=1037.850, cls=46.244, num_pos=200.000, num_neg=681208.000, B=64.000\n",
            "Grad norm: 146685.65\n",
            "Epoch [6/50], Iter [120/129], Loss: total=0.808, box=45.425, obj=962.697, noobj=942.730, cls=42.426, num_pos=204.000, num_neg=681204.000, B=64.000\n",
            "Learning Rate for this epoch: 9.649e-04\n",
            "Validation Loss: 0.8470\n",
            "Updating best val loss: 0.84700\n",
            "\n",
            "Starting epoch 7 / 50\n",
            "Grad norm: 150839.10\n",
            "Epoch [7/50], Iter [40/129], Loss: total=0.724, box=39.485, obj=841.426, noobj=817.078, cls=32.611, num_pos=201.000, num_neg=681207.000, B=64.000\n",
            "Grad norm: 159049.43\n",
            "Epoch [7/50], Iter [80/129], Loss: total=0.745, box=42.683, obj=941.896, noobj=920.193, cls=44.941, num_pos=222.000, num_neg=681186.000, B=64.000\n",
            "Grad norm: 175964.07\n",
            "Epoch [7/50], Iter [120/129], Loss: total=0.739, box=36.205, obj=1020.961, noobj=1007.592, cls=32.011, num_pos=171.000, num_neg=681237.000, B=64.000\n",
            "Learning Rate for this epoch: 9.525e-04\n",
            "Validation Loss: 0.8014\n",
            "Updating best val loss: 0.80139\n",
            "\n",
            "Starting epoch 8 / 50\n",
            "Grad norm: 171834.24\n",
            "Epoch [8/50], Iter [40/129], Loss: total=0.734, box=36.844, obj=838.382, noobj=816.778, cls=29.126, num_pos=180.000, num_neg=681228.000, B=64.000\n",
            "Grad norm: 160138.92\n",
            "Epoch [8/50], Iter [80/129], Loss: total=0.687, box=32.669, obj=885.989, noobj=873.393, cls=31.989, num_pos=171.000, num_neg=681237.000, B=64.000\n",
            "Grad norm: 174969.88\n",
            "Epoch [8/50], Iter [120/129], Loss: total=0.680, box=37.944, obj=936.439, noobj=918.523, cls=31.958, num_pos=201.000, num_neg=681207.000, B=64.000\n",
            "Learning Rate for this epoch: 9.382e-04\n",
            "Validation Loss: 0.7831\n",
            "Updating best val loss: 0.78311\n",
            "\n",
            "Starting epoch 9 / 50\n",
            "Grad norm: 164838.11\n",
            "Epoch [9/50], Iter [40/129], Loss: total=0.657, box=32.101, obj=978.646, noobj=965.147, cls=34.076, num_pos=185.000, num_neg=681223.000, B=64.000\n",
            "Grad norm: 178142.90\n",
            "Epoch [9/50], Iter [80/129], Loss: total=0.602, box=28.303, obj=887.553, noobj=875.607, cls=27.359, num_pos=172.000, num_neg=681236.000, B=64.000\n",
            "Grad norm: 171774.28\n",
            "Epoch [9/50], Iter [120/129], Loss: total=0.713, box=39.825, obj=870.813, noobj=851.784, cls=40.639, num_pos=211.000, num_neg=681197.000, B=64.000\n",
            "Learning Rate for this epoch: 9.222e-04\n",
            "Validation Loss: 0.7822\n",
            "Updating best val loss: 0.78222\n",
            "\n",
            "Starting epoch 10 / 50\n",
            "Grad norm: 171957.82\n",
            "Epoch [10/50], Iter [40/129], Loss: total=0.592, box=27.636, obj=977.068, noobj=966.949, cls=27.107, num_pos=170.000, num_neg=681238.000, B=64.000\n",
            "Grad norm: 174718.28\n",
            "Epoch [10/50], Iter [80/129], Loss: total=0.582, box=30.991, obj=855.188, noobj=844.515, cls=23.091, num_pos=178.000, num_neg=681230.000, B=64.000\n",
            "Grad norm: 135303.31\n",
            "Epoch [10/50], Iter [120/129], Loss: total=0.613, box=30.043, obj=994.882, noobj=982.789, cls=30.793, num_pos=184.000, num_neg=681224.000, B=64.000\n",
            "Learning Rate for this epoch: 9.046e-04\n",
            "Validation Loss: 0.7606\n",
            "Updating best val loss: 0.76060\n",
            "\n",
            "Evaluating on validation set...\n",
            "---Evaluate model on validation samples---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [00:41<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.35209 AP of class aeroplane\n",
            "0.25880 AP of class bicycle\n",
            "0.21045 AP of class bird\n",
            "0.03201 AP of class boat\n",
            "0.00616 AP of class bottle\n",
            "0.30020 AP of class bus\n",
            "0.21223 AP of class car\n",
            "0.44113 AP of class cat\n",
            "0.09787 AP of class chair\n",
            "0.00000 AP of class cow (no predictions for this class)\n",
            "0.28367 AP of class diningtable\n",
            "0.35949 AP of class dog\n",
            "0.41803 AP of class horse\n",
            "0.34979 AP of class motorbike\n",
            "0.47557 AP of class person\n",
            "0.00498 AP of class pottedplant\n",
            "0.00000 AP of class sheep (no predictions for this class)\n",
            "0.20057 AP of class sofa\n",
            "0.44805 AP of class train\n",
            "0.01639 AP of class tvmonitor\n",
            "--- MAP: 0.22337 ---\n",
            "Epoch 10, mAP: 0.2234\n",
            "\n",
            "Starting epoch 11 / 50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3299012821.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nStarting epoch {epoch + 1} / {num_epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Move to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "print('\\nStarting training...')\n",
        "torch.cuda.empty_cache()\n",
        "best_val_loss = np.inf\n",
        "best_map = 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    print(f'\\nStarting epoch {epoch + 1} / {num_epochs}')\n",
        "    for i, (images, target) in enumerate(train_loader):\n",
        "        # Move to device\n",
        "        images = images.to(device)\n",
        "        target = [t.to(device) for t in target]\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(\"cuda\", enabled=use_amp):\n",
        "            pred = model(images)\n",
        "            # pred and target are lists of each scales\n",
        "            loss_dict = criterion(pred, target)\n",
        "        # Backward pass with mixed precision support\n",
        "        scaler.scale(loss_dict['total']).backward()\n",
        "\n",
        "        if (i + 1) % 40 == 0:\n",
        "          total_norm = 0.0\n",
        "          for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "              total_norm += p.grad.data.norm(2).item()\n",
        "          print(f\"Grad norm: {total_norm:.2f}\")\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        # Print progress\n",
        "        if (i + 1) % 40 == 0:\n",
        "            outstring = f'Epoch [{epoch+1}/{num_epochs}], Iter [{i+1}/{len(train_loader)}], Loss: '\n",
        "            outstring += ', '.join(f\"{key}={val :.3f}\" for key, val in loss_dict.items())\n",
        "            print(outstring)\n",
        "    lr_scheduler.step()\n",
        "    learning_rate = lr_scheduler.get_last_lr()[0]\n",
        "    print(f'Learning Rate for this epoch: {learning_rate:.3e}')\n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        model.eval()\n",
        "        for i, (images, target) in enumerate(val_loader):\n",
        "            # Move to device\n",
        "            images = images.to(device)\n",
        "            target = [t.to(device) for t in target]\n",
        "            # Forward pass\n",
        "            pred = model(images)\n",
        "            loss_dict = criterion(pred, target)\n",
        "            val_loss += loss_dict['total'].item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        print(f'Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    # Save best model\n",
        "    if best_val_loss > val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        print(f'Updating best val loss: {best_val_loss:.5f}')\n",
        "        os.makedirs('checkpoints', exist_ok=True)\n",
        "        torch.save(model.state_dict(), 'checkpoints/best_detector.pth')\n",
        "\n",
        "    # Save checkpoint\n",
        "    # if (epoch + 1) in [5, 10, 20, 30, 40]:\n",
        "    #     torch.save(model.state_dict(), f'checkpoints/detector_epoch_{epoch+1}.pth')\n",
        "\n",
        "    torch.save(model.state_dict(), 'checkpoints/detector.pth')\n",
        "\n",
        "    # Evaluate on val set\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print('\\nEvaluating on validation set...')\n",
        "        val_aps = evaluate(model, eval_loader)\n",
        "        print(f'Epoch {epoch + 1}, mAP: {np.mean(val_aps):.4f}')\n",
        "        if (np.mean(val_aps) > best_map):\n",
        "            best_map = np.mean(val_aps)\n",
        "            torch.save(model.state_dict(), 'checkpoints/best_map_detector.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEHZdgi7LNGD"
      },
      "source": [
        "# Kaggle submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdMbCNG4LNGD"
      },
      "source": [
        "### Predict Result\n",
        "\n",
        "Predict the results based on testing set. Upload to [Kaggle](https://www.kaggle.com/t/3fd493e454a744bdacc7f2918f9a2605).\n",
        "\n",
        "**How to upload**\n",
        "\n",
        "1. Click the folder icon in the left hand side of Colab.\n",
        "2. Right click \"result.csv\". Select \"Download\"\n",
        "3. To kaggle. Click \"Submit Predictions\"\n",
        "4. Upload the result.csv\n",
        "5. System will automaticlaly calculate the accuracy of 50% dataset and publish this result to leaderboard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWhhbokrLNGD"
      },
      "outputs": [],
      "source": [
        "!python predict_test.py --weights checkpoints/best_map_detector.pth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MESSAGE = (\"\"\n",
        "    +f\"num_epochs={num_epochs}\\n\"\n",
        "    +f\"max_lr={learning_rate}\\n\"\n",
        "    +f\"batch_size={batch_size}\\n\"\n",
        ")\n",
        "!kaggle competitions submit -c lab-5-object-detection-on-pascal-voc-639401 -f result.csv -m \"{MESSAGE}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV28lPej-V9J",
        "outputId": "3ad5c18a-b995-40d1-990b-2899cd55a5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 591k/591k [00:00<00:00, 911kB/s]\n",
            "Successfully submitted to Lab5 Object Detection on Pascal VOC (639401)"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}